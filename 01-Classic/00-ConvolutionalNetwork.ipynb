{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some important terms for PyTorch and deep learning with CNNs\n",
    "\n",
    "**Tensor**: a multidimensional matrix for calculation. Inputs, outputs, and weights are all stored as tensors. A CNN will have an \"input\" tensor as input (one or more images), and an \"output\" tensor as the output.\n",
    "\n",
    "**Kernel**: a filter tensor or weight tensor, most often used in a convolution computation.\n",
    "\n",
    "**Channel**: when we deal with 2D feature maps, the third-from-last dimension indexes the channel or depth dimension. A 2D image stored as a tensor has three dimensions: channel, row, and column.\n",
    "\n",
    "**Feature**: could refer to the result of a convolution operation (feature \"map\") or a hand-crafted input to a model or a unit in a linear/dense/fully-connected layer.\n",
    "\n",
    "**Feature extraction**: the process of transforming raw data into numerical features that concentrate and/or preserve the useful information in the raw data.\n",
    "\n",
    "**Stride**: The jump necessary to go from one element to the next when performing an operation on an input tensor.\n",
    "\n",
    "**Padding**: Additional elements added around the boundaries of a tensor to allow convolution operations or other operations to preserve size. Padding is usually with 0 elements, but other methods include copy-border and mirror reflection.\n",
    "\n",
    "In PyTorch, we do not have to specify the input size to a convolution operation, but we do need to specify the number of input channels and the kernel size and stride. Any specific operation will lead to a specific ouptut size depending on the input size. For dense or fully-connected layers, however, we need to specify the number of input features as well as the number of output features, so it is necessary to understand how to calculate how tensor operations affect the output tensor size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the number of parameters and output tensor size for tensor operations\n",
    "\n",
    "### Convolutional layer parameters\n",
    "\n",
    "The number of parameters $k$ in a kernel for a 2D convolution operation is\n",
    "\n",
    "$$k = k_w k_h i_c,$$\n",
    "\n",
    "where $k_w$ is the width of the kernel, $k_h$ is the width of kernel, and $i_c$ is the number input channels.\n",
    "If we have $o_c$ kernels producing $o_c$ output channels, the total number of parameters/weights can be calculated as\n",
    "\n",
    "$$n_p = k o_c = k_w k_h i_c o_c.$$\n",
    "\n",
    "The bias weight in a convolution operation is optional. It's not needed if you apply normalization procedures such as\n",
    "batch normalization (almost always done in modern networks), but it is important if you're not using batch normalization.\n",
    "In that case, the number of biases is equal to the number of kernels:\n",
    "\n",
    "$$n_p = k_w k_h i_c o_c + o_c.$$\n",
    "\n",
    "### Fully connected layer parameters\n",
    "\n",
    "PyTorch separates the linear operation from the nonlinear activation function in a fully connected layer. The linear operation\n",
    "is called a \"linear\" layer, then you have to add the activation function separately. Other frameworks such as keras use the term\n",
    "\"dense layer\" for a fully connected layer including the nonlinear activation function.\n",
    "\n",
    "The number of weights $s_w$ in a linear layer is\n",
    "\n",
    "$$s_w = i_f o_f$$\n",
    "\n",
    "or\n",
    "\n",
    "$$s_w = i_f o_f + o_f$$\n",
    "\n",
    "if we include a bias weight (again, not necessary if we are going to follow up with batch normalization).\n",
    "\n",
    "It is useful to calculate the total number of parameters across all layers in a network to understand how statistically efficient it's going to be.\n",
    "\n",
    "### Convolutional layer output tensor size\n",
    "\n",
    "If we have an input tensor of size $w \\times h \\times c$ and want to perform a convolution with a $k_w \\times k_h$ kernel with padding $p$ and stride $s$,\n",
    "we can calculate the output tensor size as\n",
    "\n",
    "$$\\lfloor \\frac{w+2p-k_w}{s} + 1 \\rfloor \\times \\lfloor \\frac{h+2p-k_h}{s} + 1 \\rfloor.$$\n",
    "\n",
    "For example, in AlexNet, the input image in the first layer is $224 \\times 224 \\times 3$.\n",
    "A convolution of size $11 \\times 11$ with padding 2 and stride 4 gives an output feature map width and height of\n",
    "\n",
    "$$\\lfloor \\frac{w+2p-k_w}{s} + 1 \\rfloor = \\lfloor \\frac{224+2(2)-11}{4} + 1 \\rfloor = \\lfloor 55.25 \\rfloor = 55$$"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
