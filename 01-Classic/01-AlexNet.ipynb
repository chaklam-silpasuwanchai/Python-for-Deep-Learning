{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlexNet model\n",
    "\n",
    "This part of the lab is adapted from [kuangliu's PyTorch CIFAR repository on GitHub](https://github.com/kuangliu/pytorch-cifar/blob/master/models/googlenet.py).\n",
    "\n",
    "From class, we now know that the AlexNet model (without splitting across GPUs) looks like this:\n",
    "\n",
    "<img src=\"figures/alexnet.png\" title=\"AlexNet (Alex et al.)\" style=\"width: 900px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlexNet Coding in PyTorch\n",
    "\n",
    "First, we import some necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we set up Dataset objects and DataLoader objects to load images, transform them to 3x224x224, and batch them for training/testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Set up preprocessing of CIFAR-10 images to 3x224x224 with normalization\n",
    "# using the magic ImageNet means and standard deviations. You can try\n",
    "# RandomCrop, RandomHorizontalFlip, etc. during training to obtain\n",
    "# slightly better generalization.\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "# Download CIFAR-10 and split into training, validation, and test sets\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data/CIFAR10', train=True, download=True, transform=preprocess)\n",
    "\n",
    "# Split the training set into training and validation sets randomly.\n",
    "# CIFAR-10 train contains 50,000 examples, so let's split 80%/20%.\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [40000, 10000])\n",
    "\n",
    "# Download the test set. If you use data augmentation transforms for the training set,\n",
    "# you'll want to use a different transformer here.\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data/CIFAR10', train=False, download=True, transform=preprocess)\n",
    "\n",
    "# Dataset objects are mainly designed for datasets that can't fit entirely into memory.\n",
    "# Dataset objects don't load examples into memory until their __getitem__() method is\n",
    "# called. For supervised learning datasets, __getitem__() normally returns a 2-tuple\n",
    "# on each call. To make a Dataset object like this useful, we use a DataLoader object\n",
    "# to optionally shuffle then batch the examples in each dataset. During training.\n",
    "# To keep our memory utilization small, we'll use 4 images per batch, but we could use\n",
    "# a much larger batch size on a dedicated GPU. To obtain optimal usage of the GPU, we\n",
    "# would like to load the examples for the next batch while the current batch is being\n",
    "# used for training. DataLoader handles this by spawining \"worker\" threads that proactively\n",
    "# fetch the next batch in the background, enabling parallel training on the GPU and data\n",
    "# loading/transforming/augmenting on the CPU. Here we use num_workers=2 (the default)\n",
    "# so that two batches are always ready or being prepared.\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=4, shuffle=True, num_workers=2)\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    val_dataset,   batch_size=4, shuffle=False, num_workers=2)\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_dataset,  batch_size=4, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we set up to execute on a particular GPU or the CPU only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cpu\n"
     ]
    }
   ],
   "source": [
    "# Device 'cuda' or 'cuda:0' means GPU slot 0.\n",
    "# If you have more than one GPU, you can select other GPUs using 'cuda:1', 'cuda:2', etc.\n",
    "# In terminal (Linux), you can check memory using in each GPU by using command\n",
    "# $ nvidia-smi\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Using device', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"AlexNet\" with the Sequential API\n",
    "\n",
    "PyTorch deep learning models come in (at least) two possible styles:\n",
    "\n",
    "<img src=\"figures/NNinPytorch.png\" style=\"width: 500px;\" />\n",
    "\n",
    "1. The PyTorch Sequential API is very expressive when we have a straightforward sequence of operations to perform on the input.\n",
    "2. The PyTorch neural network Module allows more flexible transformations of inputs, combination of multiple inputs, generation of multiple outputs, and so on.\n",
    "\n",
    "We will see that AlexNet (at least a simple form of AlexNet) can mostly be expressed as a Sequential process, whereas GoogLeNet, with its\n",
    "parallel branches within Inception modules, requires the use of the Module API.\n",
    "\n",
    "### The model\n",
    "\n",
    "Let's express an AlexNet-like network using `torch.nn.Sequential`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple module to flatten a batched feature map tensor into a batched vector tensor\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        return x.view(batch_size, -1)\n",
    "\n",
    "# AlexNet-like model using the Sequential API\n",
    "\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "alexnet_sequential = nn.Sequential(\n",
    "    nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=2),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "    nn.Conv2d(96, 256, kernel_size=5, padding=2),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "    nn.Conv2d(256, 384, kernel_size=3, padding=1),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Conv2d(384, 384, kernel_size=3, padding=1),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "    nn.AdaptiveAvgPool2d((6, 6)),\n",
    "    Flatten(),\n",
    "    nn.Dropout(),\n",
    "    nn.Linear(256 * 6 * 6, 4096),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(),\n",
    "    nn.Linear(4096, 4096),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(4096, NUM_CLASSES)\n",
    ")\n",
    "\n",
    "# Move model to target device\n",
    "\n",
    "alexnet_sequential = alexnet_sequential.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, by the way, it would be useful to go back to the [AlexNet paper](https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf)\n",
    "and ask what is missing in this version of the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training function\n",
    "\n",
    "Next, let's write a function to train our model for some number of epochs. This one is adapted from the PyTorch tutorials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, weights_name='weight_save', is_inception=False):\n",
    "    '''\n",
    "    train_model function\n",
    "\n",
    "    Train a PyTorch model for a given number of epochs.\n",
    "    \n",
    "            Parameters:\n",
    "                    model: Pytorch model\n",
    "                    dataloaders: dataset\n",
    "                    criterion: loss function\n",
    "                    optimizer: update weights function\n",
    "                    num_epochs: number of epochs\n",
    "                    weights_name: file name to save weights\n",
    "                    is_inception: The model is inception net (Google LeNet) or not\n",
    "\n",
    "            Returns:\n",
    "                    model: Best model from evaluation result\n",
    "                    val_acc_history: evaluation accuracy history\n",
    "                    loss_acc_history: loss value history\n",
    "    '''\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "    loss_acc_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_start = time.time()\n",
    "\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over the train/validation dataset according to which phase we're in\n",
    "            \n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "\n",
    "                # Inputs is one batch of input images, and labels is a corresponding vector of integers\n",
    "                # labeling each image in the batch. First, we move these tensors to our target device.\n",
    "                \n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Zero out any parameter gradients that have previously been calculated. Parameter\n",
    "                # gradients accumulate over as many backward() passes as we let them, so they need\n",
    "                # to be zeroed out after each optimizer step.\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Instruct PyTorch to track gradients only if this is the training phase, then run the\n",
    "                # forward propagation and optionally the backward propagation step for this iteration.\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # The inception model is a special case during training because it has an auxiliary\n",
    "                    # output used to encourage discriminative representations in the deeper feature maps.\n",
    "                    # We need to calculate loss for both outputs. Otherwise, we have a single output to\n",
    "                    # calculate the loss on.\n",
    "                    if is_inception and phase == 'train':\n",
    "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 + 0.4 * loss2\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # Backpropagate only if in training phase\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # Gather our summary statistics\n",
    "                \n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "            epoch_end = time.time()\n",
    "            \n",
    "            elapsed_epoch = epoch_end - epoch_start\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "            print(\"Epoch time taken: \", elapsed_epoch)\n",
    "\n",
    "            # If this is the best model on the validation set so far, deep copy it\n",
    "\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                torch.save(model.state_dict(), weights_name + \".pth\")\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "            if phase == 'train':\n",
    "                loss_acc_history.append(epoch_loss)\n",
    "\n",
    "        print()\n",
    "\n",
    "    # Output summary statistics, load the best weight set, and return results\n",
    "    \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history, loss_acc_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer and loss function\n",
    "\n",
    "Before we start training, we need to set up an optimizer object and a loss function. Typical choices for the loss function:\n",
    "* For regression problems, we would normally use `nn.MSELoss()`. The equation is:\n",
    "$$MSE=\\frac{1}{N}\\sum_{i=1}^N(y_i-\\hat{y}_i)^2 $$\n",
    "* For binary classification, we normally use `nn.BCELoss()`:\n",
    "$$BCE=-\\frac{1}{N}\\sum_{i=1}^N y_i\\cdot \\log{\\hat{y}_i} + (1-y_i)\\cdot \\log(1 -{\\hat{y}_i})$$\n",
    "* For multinomial classification, we most often use `nn.CrossEntropyLoss()`:\n",
    "$$CE=-\\sum_{i=1}^C t_i\\cdot \\log(f(s)_i),$$\n",
    "where $t_i$ and $s_i$ are the ground truth and the CNN prediction for each class $i$ in $1..C$.\n",
    "An activation function (Sigmoid / Softmax) is usually applied to the scores before the CE Loss computation, so $f(s)_i$ refers to the nonlinear activation function application.\n",
    "\n",
    "For specialized needs, you can define your own loss function! We'll see examples of that later in the course.\n",
    "\n",
    "Typical choices for the optimizer:\n",
    "* SGD: Scholastic gradient descent, works well for most cases but requires appropriate values for the learning, momentum, and weight decay. Given $\\alpha$ is learning rate, and $\\beta$ is momentum, the equation is\n",
    "\n",
    "$$V_t = \\beta V_{t-1} + (1-\\beta)\\nabla_wL(W,X,y)$$\n",
    "$$W_{t+1} = W_t + \\alpha V_t$$\n",
    "\n",
    " for more information please see [Stochastic Gradient Descent with momentum](https://towardsdatascience.com/stochastic-gradient-descent-with-momentum-a84097641a5d)\n",
    "\n",
    "* Adam: adaptive learning rate optimizer that usually gives superior results to SGD but sometimes doesn't work. Adam's equations are:\n",
    "$$(m_t)_i=\\beta_1(m_{t-1})_i+(1-\\beta_1)(\\nabla(W_t))_i,$$\n",
    "$$(v_t)_i=\\beta_2(v_{t-1})_i+(1-\\beta_2)(\\nabla(W_t))_i^2,$$\n",
    "$$(W_{t+1})i=(W_t)_i-\\alpha\\frac{\\sqrt{1-(\\beta_2)_i^t}}{1-(\\beta_i)_i^t}\\frac{(m_t)_i}{\\sqrt{(v_t)_i}+\\epsilon}$$\n",
    "* See the many other choices selected from recent deep learning papers in the [PyTorch optim documentation](https://pytorch.org/docs/stable/optim.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CrossEntropyLoss for multinomial classification (because we have 10 classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# parameters = weights\n",
    "params_to_update = alexnet_sequential.parameters()\n",
    "# Use scholastic gradient descent for update weights in model with learning rate 0.001 and momentum 0.9\n",
    "optimizer = optim.SGD(params_to_update, lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "Use train_model function for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 1.7464 Acc: 0.3524\n",
      "Epoch time taken:  76.76025462150574\n",
      "val Loss: 1.3577 Acc: 0.5049\n",
      "Epoch time taken:  83.65061354637146\n",
      "\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 1.2213 Acc: 0.5644\n",
      "Epoch time taken:  76.73192644119263\n",
      "val Loss: 1.0506 Acc: 0.6226\n",
      "Epoch time taken:  83.35552620887756\n",
      "\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 0.9679 Acc: 0.6609\n",
      "Epoch time taken:  76.92400431632996\n",
      "val Loss: 0.9124 Acc: 0.6828\n",
      "Epoch time taken:  83.58274269104004\n",
      "\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 0.8160 Acc: 0.7177\n",
      "Epoch time taken:  76.84008717536926\n",
      "val Loss: 0.7564 Acc: 0.7386\n",
      "Epoch time taken:  83.81382274627686\n",
      "\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 0.7024 Acc: 0.7541\n",
      "Epoch time taken:  77.08730220794678\n",
      "val Loss: 0.8350 Acc: 0.7128\n",
      "Epoch time taken:  84.01303172111511\n",
      "\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 0.6233 Acc: 0.7858\n",
      "Epoch time taken:  77.0996687412262\n",
      "val Loss: 0.6750 Acc: 0.7672\n",
      "Epoch time taken:  84.05988454818726\n",
      "\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 0.5447 Acc: 0.8088\n",
      "Epoch time taken:  77.15944075584412\n",
      "val Loss: 0.7000 Acc: 0.7583\n",
      "Epoch time taken:  83.95197248458862\n",
      "\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 0.4846 Acc: 0.8315\n",
      "Epoch time taken:  76.93535780906677\n",
      "val Loss: 0.6381 Acc: 0.7829\n",
      "Epoch time taken:  83.76718735694885\n",
      "\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 0.4331 Acc: 0.8518\n",
      "Epoch time taken:  76.93875002861023\n",
      "val Loss: 0.6329 Acc: 0.7921\n",
      "Epoch time taken:  83.84479522705078\n",
      "\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Loss: 0.3941 Acc: 0.8630\n",
      "Epoch time taken:  77.17894458770752\n",
      "val Loss: 0.6525 Acc: 0.7852\n",
      "Epoch time taken:  83.96751356124878\n",
      "\n",
      "Training complete in 14m 0s\n",
      "Best val Acc: 0.792100\n"
     ]
    }
   ],
   "source": [
    "dataloaders = { 'train': train_dataloader, 'val': val_dataloader }\n",
    "\n",
    "best_model, val_acc_history, loss_acc_history = train_model(alexnet_sequential, dataloaders, criterion, optimizer, 10, 'alex_sequential_lr_0.001_bestsofar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlexNet using the Module API\n",
    "\n",
    "The Sequential API makes it easy to create a sequential model, but not all models are sequential. For example, we need more flexibility\n",
    "to create a complex model such as GoogLeNet.\n",
    "\n",
    "Working with the `Module` API requires us to use object-oriented inheritance in Python. This means you'll have to brush up on your OO concepts or learn the basics if OOP is new to you.\n",
    "\n",
    "We create a new class that inherits from `Module`, then in most cases, we just need to override two methods: `__init__()` and `forward()`.\n",
    "\n",
    "`__init__()` is called the \"constructor\" of a class and is the method called on any Python object just after it is created, similar to constructors in Java or C++.\n",
    "\n",
    "However, constructors and instance methods work a little differently in Python than they do in Java or C++. The constructor is just an ordinary instance method that is only special in that it\n",
    "is called implicitly when the object is created. Instance methods in Python (methods called on an object) are distinguished from class methods (methods called on the class, not requiring any\n",
    "instance) by the presence or absence of the `self` keyword in the parameter list. In the body of an instance method, `self` is a reference to the instance the method was called on, same as\n",
    "`this` in Java or C++ or `self` in Ruby.\n",
    "\n",
    "Anther difference between Python and other languages is that object initialization in an inheritance hierarchy is more flexible.\n",
    "A constructor should normally call `super(ClassName, self).__init__()` (Python 2, also works in Python 3) or `super().__init__()` (Python 3 only) at the beginning of its\n",
    "own `__init__()` method to initialze any fields used by methods in the superclass, but it need not do so.\n",
    "\n",
    "In the case of a PyTorch `Module` subclass, we should call `super()` before doing other things.\n",
    "\n",
    "The `forward()` method is also an instance method that is implicitly called when we invoke a `Module` instance as a function. So the code\n",
    "\n",
    "    module = MyModule()\n",
    "    \n",
    "creates an instance of `MyModule` and then calls its `__init__()` method, whereas\n",
    "\n",
    "    outputs = module(inputs)\n",
    "\n",
    "invokes the `forward()` method defined in `MyModule`.\n",
    "\n",
    "### The model\n",
    "\n",
    "Here's an implementation of an AlexNet-like network.\n",
    "\n",
    "Note that `Sequential` is itself a subclass of `Module`. This means we can use `Sequential` for a sequential flow in a larger network.\n",
    "\n",
    "Also note that the adaptive average pool layer between the feature module and the classifier is a trick used to ensure a fixed set of 6x6 feature maps come out\n",
    "of the feature extractor regardless of the input image size. It is not strictly required here (and not used in the original paper) but would allow us to use other input sizes besides 224x224 if we like.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNetModule(nn.Module):\n",
    "    '''\n",
    "    An AlexNet-like CNN\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    num_classes : int\n",
    "        Number of classes in the final multinomial output layer\n",
    "    features : Sequential\n",
    "        The feature extraction portion of the network\n",
    "    avgpool : AdaptiveAvgPool2d\n",
    "        Convert the final feature layer to 6x6 feature maps by average pooling if they are not already 6x6\n",
    "    classifier : Sequential\n",
    "        Classify the feature maps into num_classes classes\n",
    "    '''\n",
    "    def __init__(self, num_classes: int = 10) -> None:\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet = AlexNetModule(10).to(device)\n",
    "# Make optimizer and Loss function\n",
    "criterion_2 = nn.CrossEntropyLoss()\n",
    "params_to_update_2 = alexnet.parameters()\n",
    "optimizer_2 = optim.SGD(params_to_update_2, lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 0.8005 Acc: 0.7222\n",
      "Epoch time taken:  74.37363409996033\n",
      "val Loss: 0.7667 Acc: 0.7361\n",
      "Epoch time taken:  81.21031284332275\n",
      "\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 0.6968 Acc: 0.7586\n",
      "Epoch time taken:  72.87970519065857\n",
      "val Loss: 0.7414 Acc: 0.7506\n",
      "Epoch time taken:  79.862961769104\n",
      "\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 0.6137 Acc: 0.7868\n",
      "Epoch time taken:  76.41032123565674\n",
      "val Loss: 0.7180 Acc: 0.7534\n",
      "Epoch time taken:  83.27066278457642\n",
      "\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 0.5458 Acc: 0.8103\n",
      "Epoch time taken:  72.94309997558594\n",
      "val Loss: 0.7124 Acc: 0.7640\n",
      "Epoch time taken:  79.88523292541504\n",
      "\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 0.4960 Acc: 0.8270\n",
      "Epoch time taken:  72.0707139968872\n",
      "val Loss: 0.6915 Acc: 0.7672\n",
      "Epoch time taken:  79.07196426391602\n",
      "\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 0.4449 Acc: 0.8461\n",
      "Epoch time taken:  72.26198840141296\n",
      "val Loss: 0.6603 Acc: 0.7824\n",
      "Epoch time taken:  79.15270256996155\n",
      "\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 0.4093 Acc: 0.8586\n",
      "Epoch time taken:  76.20788049697876\n",
      "val Loss: 0.6729 Acc: 0.7780\n",
      "Epoch time taken:  83.31967234611511\n",
      "\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 0.3809 Acc: 0.8676\n",
      "Epoch time taken:  73.53619122505188\n",
      "val Loss: 0.6986 Acc: 0.7754\n",
      "Epoch time taken:  80.60638046264648\n",
      "\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 0.3558 Acc: 0.8781\n",
      "Epoch time taken:  77.32169556617737\n",
      "val Loss: 0.6887 Acc: 0.7780\n",
      "Epoch time taken:  84.13513898849487\n",
      "\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Loss: 0.3338 Acc: 0.8858\n",
      "Epoch time taken:  76.36293530464172\n",
      "val Loss: 0.6723 Acc: 0.7837\n",
      "Epoch time taken:  83.32860088348389\n",
      "\n",
      "Training complete in 13m 36s\n",
      "Best val Acc: 0.783700\n"
     ]
    }
   ],
   "source": [
    "best_model2, val_acc_history2, loss_acc_history2 = train_model(\n",
    "    alexnet, dataloaders, criterion_2, optimizer_2, 10, 'alex_module_lr_0.001_bestsofar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot results\n",
    "\n",
    "Based on these results, let's plot the validation loss/accuracy curves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_data(val_acc_history, loss_acc_history):\n",
    "    plt.plot(loss_acc_history, label = 'Validation')\n",
    "    plt.title('Loss per epoch')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.plot(val_acc_history, label = 'Validation')\n",
    "    plt.title('Accuracy per epoch')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3hUZf7+8fdnUggl1ITQSegdAqHXFURsFEUpiiKoi+gqP91dy7qr33V1i6yrrr0gFlhsiKgoKKuAoEjoHUIPoYQmNSEJz++PDG6MAQIkOZnJ/bquua7MnDNn7oxyc3jOOc8x5xwiIhL4fF4HEBGRgqFCFxEJEip0EZEgoUIXEQkSKnQRkSChQhcRCRIqdJEAYmbOzBp4nUOKJxW6FDoz22pmfbzOIRLsVOgi+WBmIV5nEDkXFbp4xsxKmdnTZpbifzxtZqX8y6LM7FMzO2RmB8xsnpn5/MvuN7OdZnbEzNabWe8zbH+imb1kZl/6151jZnVzLG/iX3bAv53rc733RTObYWbHgF/lsf0KZva6me3y5/nL6eI3s5FmNt/M/m1mP5rZupw5zayGmU33f3aSmd2WY1mImT1kZpv8uRebWe0cH93HzDaa2UEze97M7ML/K0gwUaGLl/4AdALaAK2BDsDD/mX3AclANBADPAQ4M2sM3AW0d85FApcBW8/yGTcAjwFRwDJgEoCZlQW+BCYDVYFhwAtm1jzHe4cDjwORwLd5bPtNIBNoAMQDfYFbcyzvCGz2f/YjwFQzq+xf9h//71cDGAw8kaPw7/XnuQIoD4wCjufY7lVAe7K/s+v934EIOOf00KNQH2QXbp88Xt8EXJHj+WXAVv/PfwY+Bhrkek8DYC/QBwg7x+dOBKbkeF4OyAJqA0OAebnWfxl4JMd73zrLtmOAdKB0jteGAV/7fx4JpACWY/kPwAj/52cBkTmW/RWY6P95PTDgDJ/rgG45nr8HPOD1f2M9isdDe+jipRrAthzPt/lfA3gSSAJmmdlmM3sAwDmXBIwDHgX2mtkUM6vBme04/YNz7ihwwP8ZdYGO/iGdQ2Z2iOy9+Wp5vTcPdYEwYFeO979M9t7+aTudczlnvzv9+9UADjjnjuRaVtP/c22y/7I7k905fj5O9l9UIip08VQK2cV4Wh3/azjnjjjn7nPO1QOuBu49PSThnJvsnOvmf68D/n6Wz/hp7NnMygGV/Z+xA5jjnKuY41HOOXdHjveebSrSHWTvoUfleH9551zOIZuauca3T/9+KUBlM4vMtWxnjm3XP8tni+RJhS5FJczMInI8QskeR37YzKLNLAr4E/AOgJldZWYN/IV4mOwhiiwza2xml/gPnqYBJ/zLzuQKM+tmZuFkj6UvdM7tAD4FGpnZCDML8z/am1nT/PwyzrldwCzgn2ZW3sx8ZlbfzHrmWK0qcLd/29cBTYEZ/s9fAPzV/120AkbjH98HXgMeM7OGlq2VmVXJTy4p2VToUlRmkF2+px+PAn8BEoEVwEpgif81gIbAV8BR4DvgBefcN0Ap4G/APrKHHqqSfcD0TCaTfUDyANCO7GEV/MMdfYGhZO8x7yZ7T7/UefxONwHhwBrgIPABUD3H8oX+32Mf2QdXBzvn9vuXDQNi/Z/9Edlj91/6lz1F9tj4LLL/MnsdKH0euaSEsp8P8YkEDzObCCQ75x4+17qF8NkjgVv9Q0MiRUJ76CIiQUKFLiISJDTkIiISJLSHLiISJEK9+uCoqCgXGxvr1ceLiASkxYsX73PORee1zLNCj42NJTEx0auPFxEJSGa27UzLNOQiIhIkVOgiIkFChS4iEiQ8G0MXkeCRkZFBcnIyaWlpXkcJGhEREdSqVYuwsLB8v0eFLiIXLTk5mcjISGJjY9ENlC6ec479+/eTnJxMXFxcvt+XryEXM+vnv0VX0ul5qXMtr2Bmn5jZcjNbbWa3nEd2EQlwaWlpVKlSRWVeQMyMKlWqnPe/eM5Z6P57JD4PXA40A4aZWbNcq90JrHHOtQZ6kT2laPh5JRGRgKYyL1gX8n3mZw+9A5DknNvsnDsJTAEG5FrHAZH+uavLkT1VaeZ5p8mHvYfT+L9PVnMy81RhbF5EJGDlp9Br8vNbcSXzv1tlnfYc2ZP3p5A9r/U9zrlfNK6Z3W5miWaWmJqaekGBl2w/yBvzt/LXz9de0PtFJPj06tWLmTNn/uy1p59+mrFjx55x/dMXNl5xxRUcOnToF+s8+uijjB8//qyfO23aNNasWfPT8z/96U989dVX5xu/wOSn0PPa7889o9dlZN9RvQbZd3B/zszK/+JNzr3inEtwziVER+d55eo59WtRnVu6xvLG/K18uiLlgrYhIsFl2LBhTJky5WevTZkyhWHDhp3zvTNmzKBixYoX9Lm5C/3Pf/4zffr0uaBtFYT8FHoyOe7LCNTCf9/HHG4BprpsScAWoEnBRPylBy9vSts6Fbn/gxUk7T1aWB8jIgFi8ODBfPrpp6SnpwOwdetWUlJSmDx5MgkJCTRv3pxHHnkkz/fGxsayb98+AB5//HEaN25Mnz59WL9+/U/rvPrqq7Rv357WrVtz7bXXcvz4cRYsWMD06dP53e9+R5s2bdi0aRMjR47kgw8+AGD27NnEx8fTsmVLRo0a9VO22NhYHnnkEdq2bUvLli1Zt25dgX0P+TltcRHQ0MziyL6J7VBgeK51tgO9gXlmFgM0BjYXWMpcwkN9PH9DW6589lvGTlrMtDu7UiZcZ2CKFAf/98lq1qQcLtBtNqtRnkeubn7G5VWqVKFDhw588cUXDBgwgClTpjBkyBAefPBBKleuTFZWFr1792bFihW0atUqz20sXryYKVOmsHTpUjIzM2nbti3t2rUD4JprruG2224D4OGHH+b111/nN7/5Df379+eqq65i8ODBP9tWWloaI0eOZPbs2TRq1IibbrqJF198kXHjxgEQFRXFkiVLeOGFFxg/fjyvvfZaQXxN595Dd85lAncBM4G1wHvOudVmNsbMxvhXewzoYmYrgdnA/c65fQWS8AyqVyjNs0Pj2bj3KA9NXYnmdRcp2XIOu5webnnvvfdo27Yt8fHxrF69+mfDI7nNmzePQYMGUaZMGcqXL0///v1/WrZq1Sq6d+9Oy5YtmTRpEqtXrz5rlvXr1xMXF0ejRo0AuPnmm5k7d+5Py6+55hoA2rVrx9atWy/0V/6FfO3WOudmkH2T35yvvZTj5xSyb7hbpLo1jOLePo3455cbaBdbmRGd6hZ1BBHJ5Wx70oVp4MCB3HvvvSxZsoQTJ05QqVIlxo8fz6JFi6hUqRIjR44853ndZzpVcOTIkUybNo3WrVszceJEvvnmm7Nu51w7mKVKZd+LPCQkhMzMgjshMODncrnzVw34VeNoHvtkDct3/PJItYiUDOXKlaNXr16MGjWKYcOGcfjwYcqWLUuFChXYs2cPn3/++Vnf36NHDz766CNOnDjBkSNH+OSTT35aduTIEapXr05GRgaTJk366fXIyEiOHDnyi201adKErVu3kpSUBMDbb79Nz549C+g3PbOAL3Sfz/jXkDZER5Zi7KQlHDx20utIIuKRYcOGsXz5coYOHUrr1q2Jj4+nefPmjBo1iq5du571vW3btmXIkCG0adOGa6+9lu7du/+07LHHHqNjx45ceumlNGnyv/M9hg4dypNPPkl8fDybNm366fWIiAjeeOMNrrvuOlq2bInP52PMmDEUNs/uKZqQkOAK8gYXK5IPMfjF7+jSoAoTbm6Pz6er1kSKytq1a2natKnXMYJOXt+rmS12ziXktX7A76Gf1qpWRf50dTO+WZ/Kc18neR1HRKTIBU2hA9zQsQ6D4mvyr682MG/jhV2JKiISqIKq0M2Mxwe1oGHVctwzZRkph054HUmkxNCpwwXrQr7PoCp0gDLhobx4YztOZp7izslLNImXSBGIiIhg//79KvUCcno+9IiIiPN6X1BeXlk/uhz/GNyKsZOW8MSMtTza35vzYkVKilq1apGcnMyFTronv3T6jkXnIygLHeCKltUZ1TWOCfO30K5uJa5uXcPrSCJBKyws7LzurCOFI+iGXHJ68IomtKtbiQc+1CReIhL8grrQw0J8PD+8LRFhIdzxzmKOpRfKPTdERIqFoC50gGoVInh2WDybUo/y0EeaxEtEglfQFzpA1wZR3HtpIz5elsI732/zOo6ISKEoEYUOMLZXAy5pUpU/f7qGZZrES0SCUIkpdJ/PeOr61sSUj+DOSUs4oEm8RCTIlJhCB6hYJpwXbmhL6pF0xr27jKxTGk8XkeBRogodsifxeqR/M+ZuSOXf/93odRwRkQJT4godYHiHOlwTX5NnZm9kzgZd2SYiwaFEFnr2JF4taVQ1knFTlrJTk3iJSBAokYUOUDo8hBdvbEtGluPOSZrES0QCX4ktdIB6/km8lu04xOOfnflu4CIigaBEFzpkT+I1ulscb363jenLU7yOIyJywUp8oQM8cHkTEvyTeG3c88s7eIuIBAIVOtmTeD03vC1lwkO4Y9ISTeIlIgFJhe5XrUIEzw6NZ3PqUR6Yqkm8RCTwqNBz6NIgivv6NuaT5Sm89Z0m8RKRwKJCz+WOnvXp3aQqf/lsDUu2H/Q6johIvqnQc8mexKsNMeUjuEuTeIlIAFGh56FCmTBevKEd+46e5J4pSzWJl4gEBBX6GbSsVYFH+zdn3sZ9PDtbk3iJSPGnQj+LYR1qc03bmjz73418s36v13FERM5KhX4WZsbjA1vSOCaSce8u0yReIlKsqdDPoXR4CC/c0JbMLMfYSUtIz8zyOpKISJ5U6PlQL7oc469rxfIdh3j8s7VexxERyVO+Ct3M+pnZejNLMrMH8lj+OzNb5n+sMrMsM6tc8HG9069FdW7tFsdb323j42U7vY4jIvIL5yx0MwsBngcuB5oBw8ysWc51nHNPOufaOOfaAA8Cc5xzBwojsJfuv7wJ7WMr8cCHKzWJl4gUO/nZQ+8AJDnnNjvnTgJTgAFnWX8Y8J+CCFfcnJ7Eq2ypEMa8s5ijmsRLRIqR/BR6TWBHjufJ/td+wczKAP2AD8+w/HYzSzSzxNTUwLyXZ0z5CJ4dFs+Wfce4/4MVnNJFRyJSTOSn0C2P187UYlcD88803OKce8U5l+CcS4iOjs5vxmKnS/0oft+vCZ+t3MUj01drZkYRKRZC87FOMlA7x/NawJlu7TOUIB1uye3XPepx8NhJXp67mYgwHw9d0RSzvP7uExEpGvkp9EVAQzOLA3aSXdrDc69kZhWAnsCNBZqwmDIzHri8CScysnh13hZKh4dy76WNvI4lIiXYOQvdOZdpZncBM4EQYIJzbrWZjfEvf8m/6iBglnPuWKGlLWbMjEevbk56ximenb2RiDAfY3s18DqWiJRQ+dlDxzk3A5iR67WXcj2fCEwsqGCBwucznrimJWmZWfzji/VEhIYwqluc17FEpATKV6HL2YX4jH9e15r0jFP8+dM1RISFMLxjHa9jiUgJo0v/C0hoiI9nh8Xzq8bR/GHaSqYuSfY6koiUMCr0AhQe6uPFG9vRuV4Vfvv+cj5bscvrSCJSgqjQC1hEWAiv3ZxAu7qVuGfKUr5as8frSCJSQqjQC0GZ8FAmjGxP8xrlGTtpCfM2BuZVsSISWFTohSQyIow3R3WgftVy3PZWIt9v3u91JBEJcir0QlSxTDhvj+5ArUplGD1xEUu2H/Q6kogEMRV6IYsqV4pJt3YkKrIUN0/4gVU7f/Q6kogEKRV6EYgpH8GkWztSPiKMEa8vZIPmUheRQqBCLyK1KpVh8m0dCQvxMfzVhWxOPep1JBEJMir0IlS3Slkm39YR5xw3vLaQHQeOex1JRIKICr2INagaydujO3L8ZBbDX/ueXT+e8DqSiAQJFboHmtUoz1ujOnDoWAY3vLqQvUfSvI4kIkFAhe6R1rUr8sYt7dn1YxojXvuBA8dOeh1JRAKcCt1DCbGVef3mBLbsP8ZNExby44kMryOJSABToXusS4MoXh7RjvW7jzDyjR84mp7pdSQRCVAq9GLgV42r8u9hbVmR/COjJy7ixMksryOJSABSoRcT/VpU46nrW/PD1gPc/nYi6ZkqdRE5Pyr0YmRAm5r8/dpWzNu4jzsnLSUj65TXkUQkgKjQi5nrE2rz2IDmfLV2D+PeXUamSl1E8kn3FC2GRnSOJS3jFI/PWEupUB/jB7fG5zOvY4lIMadCL6Zu61GPExlZPPXlBiLCQnh8YAvMVOoicmYq9GLsN5c04ERGFi9+s4mI0BD+eFVTlbqInJEKvRgzM35/WWPSMrKYMH8LpcN9/O6yJl7HEpFiSoVezJkZf7qqGWkZp3j+602UDgvhrksaeh1LRIohFXoAMDMeH9iC9Iwsxs/KHlO/tXs9r2OJSDGjQg8QPp/xj8GtSM88xV8+W0upsBBGdKrrdSwRKUZU6AEkNMTHv4a0IT0ziz9OW0VEqI/rEmp7HUtEigldWBRgwkN9PDe8Ld0bRnH/hyuYvjzF60giUkyo0ANQRFgIr4xIICG2Mv/v3WV8sWq315FEpBhQoQeo0uEhTBjZnla1KjB20mLeXLDV60gi4jEVegArVyqUd0Z35JImVXlk+moenb6arFPO61gi4hEVeoArWyqUl0ckMLpbHBMXbOW2txJ1kwyREipfhW5m/cxsvZklmdkDZ1inl5ktM7PVZjanYGPK2YT4jD9e1Yy/DGzBnA2pDH5xASmHTngdS0SK2DkL3cxCgOeBy4FmwDAza5ZrnYrAC0B/51xz4LpCyCrncGOnurwxsj07D55gwPPzWZF8yOtIIlKE8rOH3gFIcs5tds6dBKYAA3KtMxyY6pzbDuCc21uwMSW/ejSK5sOxXQgP8XH9y9/xxapdXkcSkSKSn0KvCezI8TzZ/1pOjYBKZvaNmS02s5vy2pCZ3W5miWaWmJqaemGJ5ZwaxUQy7c6uNKlWnjHvLOGlOZtwTgdLRYJdfgo9r/lac7dDKNAOuBK4DPijmTX6xZuce8U5l+CcS4iOjj7vsJJ/0ZGlmHJ7J65sVZ2/fb6OB6eu1C3tRIJcfi79TwZyXl9eC8h9eWIysM85dww4ZmZzgdbAhgJJKRckIiyEfw+Np15UWf793yS2HzjOize0o0KZMK+jiUghyM8e+iKgoZnFmVk4MBSYnmudj4HuZhZqZmWAjsDago0qF8LnM+7r25jx17Vm0dYDXPPifLbtP+Z1LBEpBOcsdOdcJnAXMJPskn7PObfazMaY2Rj/OmuBL4AVwA/Aa865VYUXW87X4Ha1eHt0R/YfO8mgFxaQuPWA15FEpICZVwfLEhISXGJioiefXZJt2XeMURMXsfPgCZ68rhUD2uQ+vi0ixZmZLXbOJeS1TFeKljBxUWWZekcX2tSpyD1TlvH0Vxt0BoxIkFChl0CVyobzzuiOXNu2Fk9/tZFx7y4jLSPL61gicpF0g4sSKjzUx/jrWlEvuixPzlzPzoMneHlEO6qUK+V1NBG5QNpDL8HMjDt/1YDnhsezcuePDHphAUl7j3odS0QukApduKpVDabc3onjJzMZ9MJ85ift8zqSiFwAFboAEF+nEh+N7Ur1ChHcPOEHpvyw3etIInKeVOjyk9qVy/DBHV3oXL8KD0xdyV8/X8sp3TBDJGCo0OVnykeE8cbI9tzYqQ4vz9nM2ElLOHFSZ8CIBAIVuvxCaIiPxwa04I9XNWPmmt0MeeU79h5O8zqWiJyDCl3yZGaM7hbHqyMSSNp7lAHPz2dNymGvY4nIWajQ5az6NIvhvV93xjm47qUF/HfdHq8jicgZqNDlnFrUrMC0O7sSG1WWW99MZOL8LV5HEpE8qNAlX6pViOD9MZ25pEkMj36yhkc+XkWmbpghUqyo0CXfyoSH8vKIdtzWPY43v9vGrW8lciQtw+tYIuKnQpfzEuIz/nBlM54Y1JJ5G/dx3UvfsfPQCa9jiQgqdLlAwzvWYeIt7dl58AQDnpvP8h2HvI4kUuKp0OWCdW8YzdSxXYgI8zHkle/4YHGy5lYX8ZAKXS5Kw5hIpt3ZlVY1K/Lb95dz4+sL2bJP9ywV8YIKXS5aVLlSTLm9E38Z2IIVyT9y2dNzeXb2RtIzNWWASFFSoUuB8PmMGzvVZfa9PenbLIanvtzA5c/M4/vN+72OJlJiqNClQFUtH8Fzw9sy8Zb2ZGSdYugr3/O795dz8NhJr6OJBD0VuhSKXo2rMmtcT+7oVZ+Plu6k91NzdNBUpJCp0KXQlA4P4f5+Tfjs7u7ERZXlt+8vZ9ir37MpVbe5EykMKnQpdI2rRfL+rzvzxKCWrEk5zOVPz+NfX24gLUMHTUUKkgpdioTPZwzvWIfZ9/Xi8pbVeGb2Rq54Zh4LNun+pSIFRYUuRSo6shTPDI3nrVEdyHKO4a8u5N73lrH/aLrX0UQCngpdPNGjUTQzx/Xgrl814JPlKfR+ag7vJe7QQVORi6BCF89EhIXw28sa89nd3WlYtRy//2AFQ175nqS9R7yOJhKQVOjiuUYxkbx7e2f+fm1L1u8+wuXPzOOpWet10FTkPKnQpVjw+Ywh7esw+76eXNWqBs/+N4l+T8/l2406aCqSXyp0KVaiypXiX0Pa8M7ojgDc+PpCxk1Zyj4dNBU5JxW6FEvdGkbxxbge3N27IZ+t3EXvf85hyg/bOXVKB01FzkSFLsVWRFgI917aiM/v6U7japE8MHUl17/8HRv26KCpSF7yVehm1s/M1ptZkpk9kMfyXmb2o5kt8z/+VPBRpaRqUDWSd2/vxJODW5GUepQrnpnHkzPX6aCpSC6h51rBzEKA54FLgWRgkZlNd86tybXqPOfcVYWQUQQz47qE2lzSpCpPzFjH819v4pPlu3hsYAt6Nor2Op5IsZCfPfQOQJJzbrNz7iQwBRhQuLFE8lalXCn+eX1rJt/WkVCfcfOEH7j7P0vZeyTN62ginstPodcEduR4nux/LbfOZrbczD43s+YFkk7kDLrUj+Lzcd0Z16chX6zaTe9/zmHSwm06aColWn4K3fJ4LfefmiVAXedca+DfwLQ8N2R2u5klmlliamrq+SUVyaVUaAjj+jTi83HdaVGjAn/4aBWDX1rA+t06aColU34KPRmoneN5LSAl5wrOucPOuaP+n2cAYWYWlXtDzrlXnHMJzrmE6GiNe0rBqB9djsm3deSf17Vm6/7jXPmsrjSVkik/hb4IaGhmcWYWDgwFpudcwcyqmZn5f+7g365uJilFxsy4tl0tvrq3J/1bZ19pesWz8/hhywGvo4kUmXMWunMuE7gLmAmsBd5zzq02szFmNsa/2mBglZktB54FhjpNmyceqFw2nKeGtOHNUR04mXmK61/+joc+WsnhtAyvo4kUOvOqdxMSElxiYqInny0lw/GTmTw1awMT5m8hqlwp/jygBf1aVPM6lshFMbPFzrmEvJbpSlEJWmXCQ3n4qmZMu7MrVcqVYsw7ixnz9mL2HNYpjhKcVOgS9FrVqsj0u7ry+36N+Xr9Xvo8NYfJCzUvjAQfFbqUCGEhPsb2asAX43rQokYFHvpoJUNf/Z5NqUe9jiZSYFToUqLERZVl8m0d+ce1rVi36zCXPzOP5/67kZOZp7yOJnLRVOhS4pgZ17evzVf39eTSpjGMn7WB/s99y9LtB72OJnJRVOhSYlWNjOD5G9ry6k0JHDqewTUvLuD/PlnNsfRMr6OJXBAVupR4lzaL4ct7e3Bjx7pMXLCVvv+ay9fr93odS+S8qdBFgMiIMB4b2IIPxnSmdHgIt7yxiHt06zsJMCp0kRza1a3MZ3d3Y1yfhsxYuYs+T83hw8XJ6MJnCQQqdJFcTs/iOOPu7tSPLsd97y/npgk/sH3/ca+jiZyVCl3kDBrGRPL+rzvz2IDmLN1+iL5Pz+GVuZvIzNIpjlI8qdBFzsLnM0Z0juXLe3vQrUEUT8xYx8AX5rNq549eRxP5BRW6SD5Ur1CaV29K4Pnhbdn9YzoDnp/PXz9fy4mTmnNdig8Vukg+mRlXtqrO7Ht7MrhtLV6es5l+z8xlQdI+r6OJACp0kfNWoUwYfx/cism3dcSA4a8t5HfvL+fQ8ZNeR5MSToUucoG61I/ii3E9uKNXfaYu3Umfp+bw6YoUneIonlGhi1yEiLAQ7u/XhOl3daVGxdLcNXkpt76ZSMqhE15HkxJIhS5SAJrXqMDUO7rw8JVNWbBpP5c+NYcnZqxlp4pdipBuQSdSwHYcOM7fv1jH56t2A3Bly+rc2j2OVrUqepxMgsHZbkGnQhcpJMkHj/Pmgq3854cdHE3PpENsZW7tHkfvpjGE+MzreBKgVOgiHjqSlsG7i3bwxvyt7Dx0gtgqZRjVLY7B7WpRJjzU63gSYFToIsVAZtYpvli9m1fnbWH5jkNUKB3GDR3rcHOXWGLKR3gdTwKECl2kGHHOsXjbQV6bt4WZa3YT6jOubl2DW7vVo1mN8l7Hk2LubIWuf++JFDEzIyG2Mgmxldm2/xhvzN/Ke4k7mLpkJ10bVOHWbvXo2Sgan8bZ5TxpD12kGPjxeAaTf9jOxAVb2HM4nfrRZRndrR7XtK1JRFiI1/GkGNGQi0iAOJl5ihkrd/HqvM2sTjlM5bLh3NipLiM61SU6spTX8aQYUKGLBBjnHN9vPsDr327mq7V7CQ/1MahNTUZ3j6NRTKTX8cRDGkMXCTBmRuf6VehcvwqbUo8y4dstfLgkmXcTd9CzUTS3do+jW4MozDTOLv+jPXSRAHHg2EkmL9zGxAXb2Hc0nSbVIhndLY7+bWpQKlTj7CWFhlxEgkh6ZhbTl6Xw+rdbWLf7CFHlSnFz57rc2KkulcqGex1PCpkKXSQIOef4Nmkfr83bwpwNqUSE+bi2bS1Gd4ujXnQ5r+NJIdEYukgQMjO6N4yme8NoNuw5wuvztvB+YjKTFm6nT9OqjO5Wj071KmucvQTRHrpIEEk9ks7b32/jne+3ceDYSZpVL8+17WpxdevqVI3U9ALBQEMuIiVMWkYWHy3dyTvfb2N1ymF8Bl0bRDGgTU0uax5DZESY1xHlAl10oZtZP+AZIAR4zTn3tzOs1x74HhjinPvgbNtUoYsUjaS9R5i2NIWPl+9kx4ETlAr10QBA7AMAAAkUSURBVKdZDAPb1KRno2jCQ3Wfm0ByUYVuZiHABuBSIBlYBAxzzq3JY70vgTRgggpdpHhxzrFk+0GmLU3h0xUpHDyeQcUyYVzRsjqD4mvSrk4lzR8TAC72oGgHIMk5t9m/sSnAAGBNrvV+A3wItL+IrCJSSMyMdnUr065uZf50dTPmbUxl2tIUpi5JZvLC7dSsWJoBbWowML6mrkYNUPkp9JrAjhzPk4GOOVcws5rAIOASzlLoZnY7cDtAnTp1zjeriBSQsBAflzSJ4ZImMRxLz2TWmt1MW5rCy3M388I3m2havTwD29Sgf5saVK9Q2uu4kk/5KfS8/g2We5zmaeB+51zW2U6Rcs69ArwC2UMu+Q0pIoWnbKlQBsXXYlB8LVKPpPPpihSmLUvhr5+v429frKNjXGUGtqnJ5S2rU6G0DqYWZ/kZQ+8MPOqcu8z//EEA59xfc6yzhf8VfxRwHLjdOTftTNvVGLpI8bZl3zE+XraTj5elsGXfMcJDfFzSpCoD42vQq3FVTevrkYs9KBpK9kHR3sBOsg+KDnfOrT7D+hOBT3VQVCQ4OOdYkfwj05bt5JPlu9h3NJ3IiFCuaFGdAfE16BRXRQdTi9BFHRR1zmWa2V3ATLJPW5zgnFttZmP8y18q0LQiUqyYGa1rV6R17Yr84YqmLNi0n2nLdvLpihTeTdxBtfIR9G9TgwFtatCsenldmeohXVgkIhfkxMksvlq7h4+X7eSb9alknnI0rFqOgfE16d+6BrUrl/E6YlDSlaIiUqgOHDvJZyt38fHSnSRuOwhA+9hKDGhTkytbVtcskAVIhS4iRWbHgeNMX57CtKU72bj3KGEh2ZOIXdY8ht5NY4gqp1vpXQwVuogUOecca3Yd5uNlKXy2Yhc7D53AZ5BQtzJ9m8fQt1k16lTRsMz5UqGLiKdOl/us1XuYtWYPa3cdBqBJtUj6Nq9G32YxNK+hA6r5oUIXkWJl+/7jzFqzm1lr9pC49QCnHNSsWPqnPff2sZUIDdGkYXlRoYtIsbX/aDqz1+5l1prdzN24j5OZp6hUJozeTWPo2yyG7g2jKR2ui5hOU6GLSEA4lp7JvI2pzFy9h9lr93A4LZOIMB89GkZzWfNqXNKkaok/Y0a3oBORgFC2VCj9WlSnX4vqZGSd4octB5i5evdPY+8hPqNDrP+gavNq1KyoicNy0h66iBR7zjlW7vyRWav3MHP1bjbuPQpAi5rl6dusGpc1r0ajmHIl4qCqhlxEJKhsTj3Kl2uyy33pjkM4B3WrlKFvsxgua16N+DqVCAnS+WVU6CIStPYeTuOrtXuZuXo3CzbtIyPLEVUunD5NY+jbPIYu9aOCamZIFbqIlAhH0jL4Zn0qs9bs4et1ezmanknZ8BB6Na5K3+Yx9GpUlQplAntOdxW6iJQ46ZlZfLdpP7PW7OHLNXtIPZKOz6BN7Yr0aBRN94bRtK5VIeDOd1ehi0iJduqUY+mOQ8xZv5c5G/exIjl73L18RChdG0TRo1E0PRpFB8RZMyp0EZEcDh0/ybdJ+5i7IZW5G/ax+3AaAPWjy9K9YTQ9G0XTsV5lyoQXvzO7VegiImfgnCNp71HmbEhl3sZ9LNyyn7SMU4SH+EiIrZS9994wmqbVI4vFaZEqdBGRfErLyGLR1gPM25i9B79u9xEAosqVokfD7OGZbg2jPJsGWIUuInKB9hxO+6ncv03ax4FjJwFoXqO8/+BqFAl1KxMeWjQHV1XoIiIF4NQpx+qUw8zdmMqcDaks2XaQzFOOMuEhdKpX5ac9+LiosoU2PKNCFxEpBEfTM/lu037mbkhl3sZUtu4/DkCtSqX9B1ej6NIgivIRBXfuuwpdRKQIbN9/nDkbU5m3IZUFm/ZzND2TEJ9ln/veMJoejaJoVaviRU1LoEIXESliGVmnWLr9EPM2pjJ3Qyordv6Ic1ChdBi/uaQBt3avd0Hb1fS5IiJFLCzER4e4ynSIq8x9fRtz4NhJ5vvPfY8pH1Eon6lCFxEpApXLhnN16xpc3bpGoX1GYE1iICIiZ6RCFxEJEip0EZEgoUIXEQkSKnQRkSChQhcRCRIqdBGRIKFCFxEJEp5d+m9mqcC2C3x7FLCvAOMEOn0fP6fv43/0XfxcMHwfdZ1z0Xkt8KzQL4aZJZ5pLoOSSN/Hz+n7+B99Fz8X7N+HhlxERIKECl1EJEgEaqG/4nWAYkbfx8/p+/gffRc/F9TfR0COoYuIyC8F6h66iIjkokIXEQkSAVfoZtbPzNabWZKZPeB1Hi+ZWW0z+9rM1prZajO7x+tMXjOzEDNbamafep3Fa2ZW0cw+MLN1/v9HOnudyStm9v/8f0ZWmdl/zKxwbhnksYAqdDMLAZ4HLgeaAcPMrJm3qTyVCdznnGsKdALuLOHfB8A9wFqvQxQTzwBfOOeaAK0pod+LmdUE7gYSnHMtgBBgqLepCkdAFTrQAUhyzm12zp0EpgADPM7kGefcLufcEv/PR8j+A1vT21TeMbNawJXAa15n8ZqZlQd6AK8DOOdOOucOeZvKU6FAaTMLBcoAKR7nKRSBVug1gR05nidTggssJzOLBeKBhd4m8dTTwO+BU14HKQbqAanAG/4hqNfMrKzXobzgnNsJjAe2A7uAH51zs7xNVTgCrdAtj9dK/HmXZlYO+BAY55w77HUeL5jZVcBe59xir7MUE6FAW+BF51w8cAwokceczKwS2f+SjwNqAGXN7EZvUxWOQCv0ZKB2jue1CNJ/OuWXmYWRXeaTnHNTvc7joa5AfzPbSvZQ3CVm9o63kTyVDCQ7507/i+0Dsgu+JOoDbHHOpTrnMoCpQBePMxWKQCv0RUBDM4szs3CyD2xM9ziTZ8zMyB4jXeuce8rrPF5yzj3onKvlnIsl+/+L/zrngnIvLD+cc7uBHWbW2P9Sb2CNh5G8tB3oZGZl/H9mehOkB4hDvQ5wPpxzmWZ2FzCT7CPVE5xzqz2O5aWuwAhgpZkt87/2kHNuhoeZpPj4DTDJv/OzGbjF4zyecM4tNLMPgCVknxm2lCCdAkCX/ouIBIlAG3IREZEzUKGLiAQJFbqISJBQoYuIBAkVuohIkFChi4gECRW6iEiQ+P9dWkNRcOlaywAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_data(val_acc_history2, loss_acc_history2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "c81d839d3c4227cd770621df97fe8191838af02e7eef185a922d8250cb33d344"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
